# Context-Aware Research Assistant

**Version**: 0.1.0-mvp  
**Status**: âœ… Production Ready  
**Last Updated**: November 13, 2025

---

## Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure environment
cp .env.example .env
# Edit .env with your API keys (GOOGLE_API_KEY, MILVUS_HOST, etc.)

# 3. Start services
docker-compose up -d

# 4. Run tests (optional)
pytest tests/ -v

# 5. Start application
streamlit run src/pages/search.py
```

Open browser to `http://localhost:8501`

---

## Features

- **4 Parallel Sources**: RAG (Milvus), Web (Firecrawl), Academic (Arxiv), Memory (Zep)
- **Quality Evaluation**: 4-factor scoring (30% reputation + 20% recency + 40% relevance + 10% dedup)
- **3-Level Citations**: Main answer â†’ sections â†’ per-claim confidence
- **Contradiction Handling**: Explicit documentation of conflicting perspectives
- **Error Resilience**: Continues functioning when individual sources fail
- **Performance**: 15-20s typical response time (<30s guaranteed)

---

## Documentation

| Document | Purpose |
|----------|---------|
| **SETUP.md** | Installation, configuration, troubleshooting |
| **ARCHITECTURE.md** | System design, workflows, data models |
| **docs/DEPLOYMENT_CHECKLIST.md** | Production deployment steps |
| **docs/MANUAL_TESTING_GUIDE.md** | Test scenarios and procedures |
| **docs/SPECIFICATION_VERIFICATION_REPORT.md** | Requirement compliance audit |
| **specs/** | Feature specifications and implementation tasks |

---

## Project Structure

```
src/
â”œâ”€â”€ services/          # Core business logic
â”‚   â”œâ”€â”€ orchestrator.py    (Complete workflow)
â”‚   â”œâ”€â”€ evaluator.py       (Quality scoring)
â”‚   â””â”€â”€ synthesizer.py     (Response generation)
â”œâ”€â”€ models/            # Data structures
â”œâ”€â”€ tools/             # Retrieval tools (RAG, Web, Arxiv, Memory)
â”œâ”€â”€ pages/             # Streamlit UI
â””â”€â”€ logging_config.py  # Observability

tests/
â”œâ”€â”€ test_phase4_integration.py  (16 tests)
â”œâ”€â”€ test_phase5_integration.py  (13 tests)
â”œâ”€â”€ test_phase6_integration.py  (18 tests)
â””â”€â”€ test_phase7_integration.py  (14 tests)

specs/
â””â”€â”€ 001-context-aware-research/
    â”œâ”€â”€ spec.md        (6 user stories, requirements)
    â”œâ”€â”€ tasks.md       (81 implementation tasks)
    â””â”€â”€ ...
```

---

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific phase
pytest tests/test_phase7_integration.py -v

# With coverage
pytest tests/ --cov=src --cov-report=html
```

**Status**: 61/61 tests passing âœ…

---

## Architecture

```
User Query
    â†“
[Orchestrator] â† Main workflow engine
    â†“
[Retrieval] â† 4 sources in parallel
    â”œâ”€â”€ RAG (Milvus)
    â”œâ”€â”€ Web (Firecrawl)
    â”œâ”€â”€ Academic (Arxiv)
    â””â”€â”€ Memory (Zep)
    â†“
[Evaluation] â† Quality filtering
    â†“
[Synthesis] â† Response generation
    â†“
[Memory] â† Store for future queries
    â†“
[Response] â† JSON with citations
```

See `ARCHITECTURE.md` for detailed diagrams and workflows.

---

## Requirements

- Python 3.10+
- Docker & Docker Compose
- 8GB RAM (16GB recommended)
- API Keys:
  - Google Gemini API
  - Firecrawl API (optional)

---

## Performance

| Phase | Target | Typical | Max |
|-------|--------|---------|-----|
| Retrieval | 15s | 8-10s | 15s |
| Evaluation | 5s | 2-3s | 5s |
| Synthesis | 8s | 4-6s | 8s |
| Memory | 2s | 0.5-1s | 2s |
| **Total** | **30s** | **15-20s** | **30s** |

---

## Specification Compliance

âœ… **User Stories**: 6/6 (100%)  
âœ… **Requirements**: 22/22 (100%)  
âœ… **Test Coverage**: 61/61 (100%)  
âœ… **Edge Cases**: 7/7 (100%)  

See `docs/SPECIFICATION_VERIFICATION_REPORT.md` for detailed audit.

---

## Support

For questions or issues:
1. Check `SETUP.md` troubleshooting section
2. Review `ARCHITECTURE.md` for design decisions
3. See `docs/MANUAL_TESTING_GUIDE.md` for test procedures

---

## License

[Your License Here]

---

**Ready to deploy. See SETUP.md to get started.** ðŸš€

